# Model configuration
MODEL_CONFIG = {
    "model": "gpt-4.1-nano",
    "temperature": 0.3,  # Lower temperature for more consistent, professional responses
    "max_tokens": None,  # Let the model decide appropriate response length
}
